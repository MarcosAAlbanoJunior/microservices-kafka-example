# ğŸš€ MicroserviÃ§os com Apache Kafka - Guia de Estudos

Este repositÃ³rio demonstra a implementaÃ§Ã£o de microserviÃ§os utilizando Apache Kafka como sistema de mensageria, com padrÃµes de Producer e Consumer para comunicaÃ§Ã£o assÃ­ncrona entre serviÃ§os.

## ğŸ“‹ Ãndice
- [VisÃ£o Geral](#-visÃ£o-geral)
- [Arquitetura](#-arquitetura)
- [Conceitos Kafka](#-conceitos-kafka)
- [ConfiguraÃ§Ãµes do Projeto](#-configuraÃ§Ãµes-do-projeto)
- [Como Executar](#-como-executar)
- [Testando a AplicaÃ§Ã£o](#-testando-a-aplicaÃ§Ã£o)
- [Monitoramento](#-monitoramento)

## ğŸ¯ VisÃ£o Geral

O projeto implementa dois microserviÃ§os:
- **Products Microservice** (Producer): Publica eventos de criaÃ§Ã£o de produtos
- **Email Notification Microservice** (Consumer): Consome eventos e processa notificaÃ§Ãµes por email

### Tecnologias Utilizadas
- **Apache Kafka** - Sistema de streaming de eventos
- **Spring Boot** - Framework para microserviÃ§os
- **Spring Kafka** - IntegraÃ§Ã£o Spring com Kafka
- **Docker & Docker Compose** - ContainerizaÃ§Ã£o

## ğŸ—ï¸ Arquitetura

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    produce    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    consume    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º  â”‚                 â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º â”‚                         â”‚
â”‚ Products        â”‚               â”‚ Kafka Cluster   â”‚              â”‚ Email Notification      â”‚
â”‚ Microservice    â”‚               â”‚ (3 Brokers)     â”‚              â”‚ Microservice            â”‚
â”‚ (Producer)      â”‚               â”‚                 â”‚              â”‚ (Consumer)              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“š Conceitos Kafka

### ğŸª **Brokers**
Os brokers sÃ£o os servidores Kafka que formam o cluster. No projeto temos **3 brokers**:
- `kafka-1:9090` (porta externa: 9092)
- `kafka-2:9090` (porta externa: 9094) 
- `kafka-3:9090` (porta externa: 9096)

**Por que 3 brokers?**
- âœ… **Alta Disponibilidade**: Se um broker falhar, os outros continuam funcionando
- âœ… **DistribuiÃ§Ã£o de Carga**: As partiÃ§Ãµes sÃ£o distribuÃ­das entre os brokers
- âœ… **TolerÃ¢ncia a Falhas**: Permite replicaÃ§Ã£o com fator 3

### ğŸ“‚ **Topics**
Topics sÃ£o categorias onde as mensagens sÃ£o armazenadas. No projeto:
- **Topic**: `product-created-events-topic`
- **PartiÃ§Ãµes**: 3 (distribuÃ­das pelos 3 brokers)
- **RÃ©plicas**: 3 (cada partiÃ§Ã£o tem 3 cÃ³pias)

```java
@Bean
public NewTopic createTopic() {
    return TopicBuilder.name(PRODUCT_CREATED_EVENTS_TOPIC)
            .partitions(3)        // 3 partiÃ§Ãµes para paralelismo
            .replicas(3)          // 3 rÃ©plicas para redundÃ¢ncia
            .configs(Map.of("min.insync.replicas", "2"))  // MÃ­nimo 2 rÃ©plicas sincronizadas
            .build();
}
```

### ğŸ”€ **Partitions (PartiÃ§Ãµes)**
PartiÃ§Ãµes permitem paralelismo e escalabilidade:
- **3 partiÃ§Ãµes** = atÃ© 3 consumers simultÃ¢neos
- Mensagens com a mesma **chave** (productId) vÃ£o para a mesma partiÃ§Ã£o
- Garante **ordem** de mensagens por chave

### ğŸ“¤ **Producer (Products Microservice)**
O producer publica mensagens no Kafka. Implementamos **duas estratÃ©gias**:

#### **SÃ­ncrono** (`/products/sync`)
```java
SendResult<String, ProductCreatedEvent> result = kafkaTemplate
    .send(TOPIC, productId, event)
    .get(30, TimeUnit.SECONDS);  // Espera confirmaÃ§Ã£o por atÃ© 30s
```
- âœ… **Garantia de entrega**: Aguarda confirmaÃ§Ã£o
- âŒ **Menor throughput**: Bloqueia atÃ© confirmaÃ§Ã£o
- ğŸ¯ **Use quando**: Dados crÃ­ticos que precisam ser confirmados

#### **AssÃ­ncrono** (`/products/async`)
```java
CompletableFuture<SendResult<String, ProductCreatedEvent>> future =
    kafkaTemplate.send(TOPIC, productId, event);

future.whenComplete((result, exception) -> {
    // Processa resultado de forma assÃ­ncrona
});
```
- âœ… **Alto throughput**: NÃ£o bloqueia
- âŒ **Menos garantias**: PossÃ­vel perda em casos extremos
- ğŸ¯ **Use quando**: Performance Ã© mais importante que garantia absoluta

### ğŸ“¥ **Consumer (Email Notification Microservice)**
O consumer processa as mensagens do topic. Principais configuraÃ§Ãµes:

```java

@KafkaListener(topics = "product-created-events-topic")
public void consumeProductCreatedEvent(ProductCreatedEvent event) {
    // Processa evento
}
```

### âš ï¸ **DLT (Dead Letter Topic)**
**Conceito**: Quando uma mensagem falha no processamento apÃ³s vÃ¡rias tentativas, ela Ã© enviada para um "topic de mensagens mortas" para anÃ¡lise posterior.

**ImplementaÃ§Ã£o tÃ­pica**:
```java
@RetryableTopic(
        attempts = "5",
        backoff = @Backoff(delay = 1000, multiplier = 2.0, maxDelay = 30000),
        dltTopicSuffix = ".DLT"
)
@KafkaListener(topics="product-created-events-topic", groupId = "product-created-events")
public class ProductCreatedEventHandler {
}
```

## âš™ï¸ ConfiguraÃ§Ãµes do Projeto

### ğŸ”§ **ConfiguraÃ§Ãµes de Reliability**

```java
// Garante que todas as rÃ©plicas confirmem a escrita
spring.kafka.producer.acks=all

// Evita duplicaÃ§Ã£o de mensagens
spring.kafka.producer.properties.enable.idempotence=true

// Controla quantas requisiÃ§Ãµes podem estar "em voo" simultaneamente
spring.kafka.producer.properties.max.in.flight.requests.per.connection=5
```

### â±ï¸ **ConfiguraÃ§Ãµes de Timeout**

```java
// Tempo total para entrega da mensagem (2 minutos)
spring.kafka.producer.properties.delivery.timeout.ms=120000

// Tempo para aguardar resposta do broker (30 segundos)
spring.kafka.producer.properties.request.timeout.ms=30000

// Tempo para aguardar batch de mensagens (0 = envio imediato)
spring.kafka.producer.properties.linger.ms=0
```

### ğŸ“ **ConfiguraÃ§Ãµes de SerializaÃ§Ã£o**

```java
// Chave como String
spring.kafka.producer.key-serializer=StringSerializer

// Valor como JSON
spring.kafka.producer.value-serializer=JsonSerializer

// Remove headers de tipo (mais limpo)
spring.kafka.producer.properties.spring.json.add.type.headers=false
```

### ğŸ›¡ï¸ **ConfiguraÃ§Ãµes de ConsistÃªncia**

```java
// No cÃ³digo Java - mÃ­nimo de rÃ©plicas que devem confirmar
.configs(Map.of("min.insync.replicas", "2"))

// 3 rÃ©plicas com mÃ­nimo 2 sincronizadas = tolerÃ¢ncia a 1 falha
```

## ğŸš€ Como Executar

### 1. **PrÃ©-requisitos**
- Docker e Docker Compose
- Java 17+
- Maven

### 2. **Iniciando o Ambiente**
```bash
# Clona o repositÃ³rio
git clone https://github.com/MarcosAAlbanoJunior/microservices-kafka-example
cd microservices-kafka-example

# Inicia Kafka + MicroserviÃ§os
docker-compose -f docker-compose.yml --env-file environment.env up
obs: O processo pode levar alguns minutos, jÃ¡ que os microserviÃ§os dependem do Kafka estar pronto. Durante esse tempo, vocÃª verÃ¡ vÃ¡rias mensagens de inicializaÃ§Ã£o nos logs. Aguarde atÃ© que todos os serviÃ§os estejam marcados como healthy antes de comeÃ§ar a utilizÃ¡-los. Vai aparecer erros de org.apache.kafka.clients.NetworkClient atÃ© estabilizarem.

# Inicia apenas o Kafka
Caso preferir inciar sÃ³ o kafka via docker e iniciar os microsserviÃ§os pela sua IDE use este compose
docker-compose -f docker-compose-kafka.yml --env-file environment.env up
```

### 3. **Verificando o Cluster**
```bash
# Lista topics
docker exec kafka-1 kafka-topics.sh --bootstrap-server localhost:9090 --list

# Descreve o topic
docker exec kafka-1 kafka-topics.sh --bootstrap-server localhost:9090 --describe --topic product-created-events-topic
```

## ğŸ§ª Testando a AplicaÃ§Ã£o

### **Criar Produto (SÃ­ncrono)**
```bash
curl -X POST http://localhost:8081/products/sync \
  -H "Content-Type: application/json" \
  -d '{
    "title": "Notebook Gamer",
    "price": 2500.00,
    "quantity": 10
  }'
```

### **Criar Produto (AssÃ­ncrono)**
```bash
curl -X POST http://localhost:8081/products/async \
  -H "Content-Type: application/json" \
  -d '{
    "title": "Mouse Gamer",
    "price": 150.00,
    "quantity": 50
  }'
```

### **Monitorar Mensagens**
```bash
# Consome mensagens do topic
docker exec kafka-1 kafka-console-consumer.sh \
  --bootstrap-server localhost:9090 \
  --topic product-created-events-topic \
  --from-beginning \
  --property print.key=true
```

## ğŸ“Š Monitoramento

### **Logs dos MicroserviÃ§os**
```bash
# Products Microservice
docker logs products-microservice -f

# Email Notification Microservice  
docker logs email-notification-microservice -f
```

### **MÃ©tricas do Cluster**
```bash
# Status dos brokers
docker exec kafka-1 kafka-broker-api-versions.sh \
  --bootstrap-server kafka-1:9090,kafka-2:9090,kafka-3:9090

# Consumer groups
docker exec kafka-1 kafka-consumer-groups.sh \
  --bootstrap-server localhost:9090 --list
```

## ğŸ“ Aprendizados

### **Quando usar SÃ­ncrono vs AssÃ­ncrono?**

| CenÃ¡rio | SÃ­ncrono | AssÃ­ncrono |
|---------|----------|------------|
| **Pagamentos** | âœ… | âŒ |
| **Auditoria** | âœ… | âŒ |
| **NotificaÃ§Ãµes** | âŒ | âœ… |
| **Logs/MÃ©tricas** | âŒ | âœ… |
| **Alto Volume** | âŒ | âœ… |

### **ConfiguraÃ§Ãµes por CenÃ¡rio**

| CenÃ¡rio | acks | idempotence | min.insync.replicas |
|---------|------|-------------|-------------------|
| **MÃ¡xima Confiabilidade** | all | true | 2+ |
| **Alto Throughput** | 1 | false | 1 |
| **Balanceado** | all | true | 2 |

## ğŸ”— Recursos Ãšteis

- [Kafka Documentation](https://kafka.apache.org/documentation/)
- [Spring Kafka Reference](https://spring.io/projects/spring-kafka)
- [Kafka Best Practices](https://kafka.apache.org/documentation/#bestpractices)

---

**ğŸ’¡ Dica**: Este projeto Ã© ideal para entender conceitos fundamentais do Kafka. Experimente modificar as configuraÃ§Ãµes e observar o comportamento!